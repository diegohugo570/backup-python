{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-MdAVXTefQW0",
        "ObT4TEq4zinQ",
        "OPuFRccbz6WW",
        "V1KTuutr3IeA",
        "q2quM4EB4OwC",
        "1T5nCNPb5E0R"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfd68d0a4287439fbabbb65e45f5dc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd69cb2bd2cf4a0ea8ca03aa203023c6",
              "IPY_MODEL_cc2c144688c645babbfac89debeae81e",
              "IPY_MODEL_d43ba828c8c84e5a8967e08bcdf83f4b"
            ],
            "layout": "IPY_MODEL_9be006eb6cbc4b478e97fbdcaf7f13a2"
          }
        },
        "cd69cb2bd2cf4a0ea8ca03aa203023c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0128dc87f6d5433b9f993fcc7de217cc",
            "placeholder": "​",
            "style": "IPY_MODEL_6733612b234a4199abb7077447b6f637",
            "value": "model.safetensors: 100%"
          }
        },
        "cc2c144688c645babbfac89debeae81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a673a0a7984e93a9220e012edc341b",
            "max": 819960,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57ba112230a54a229d2a93b58d253334",
            "value": 819960
          }
        },
        "d43ba828c8c84e5a8967e08bcdf83f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ce8bfe1aa3494dbb616f2502184deb",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd48e26ae454efbb1e73865e85fa0f6",
            "value": " 820k/820k [00:00&lt;00:00, 8.72MB/s]"
          }
        },
        "9be006eb6cbc4b478e97fbdcaf7f13a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0128dc87f6d5433b9f993fcc7de217cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6733612b234a4199abb7077447b6f637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a673a0a7984e93a9220e012edc341b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57ba112230a54a229d2a93b58d253334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15ce8bfe1aa3494dbb616f2502184deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd48e26ae454efbb1e73865e85fa0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegohugo570/backup-python/blob/main/01_LLM_Routing_DascIA_Academy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Routing\n",
        "Fala, pessoal! Vamos começar mais um material prático aqui da Formação Arquiteto de IA.\n",
        "\n",
        "E nesse material vamos explorar as principais técnicas de LLM Routing modernas, abrangindo as principais técnicas:\n",
        "- Router preditivo\n",
        "- Router não-preditivo\n",
        "- Router híbrido\n",
        "\n",
        "As características principais dessa biblioteca são:\n",
        "- **Substituição direta do cliente da OpenAI** (ou execução de um servidor compatível com OpenAI) para rotear consultas mais simples para modelos mais baratos.\n",
        "- **Roteadores treinados são fornecidos prontos para uso**, e já demonstramos que eles reduzem os custos em até 85%, mantendo 95% da performance do GPT-4 em benchmarks amplamente utilizados como o MT Bench.\n",
        "- Os benchmarks também mostram que esses roteadores atingem a mesma performance de soluções comerciais, **sendo mais de 40% mais baratos**.\n",
        "- **O framework pode ser facilmente estendido para incluir novos roteadores** e comparar a performance entre eles em diversos benchmarks.\n",
        "\n",
        "Então, vamos começar instalando as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "-MdAVXTefQW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Router Preditivo"
      ],
      "metadata": {
        "id": "ObT4TEq4zinQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KQ1yEd0OZET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295026b5-9583-4a5a-9f78-777c6c413341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Instalando o routellm e o gradio\n",
        "!pip install -qU \"routellm[serve,eval]\" gradio groq openai --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração Inicial\n",
        "Antes de continuarmos, é importante mencionar que vamos usar de referência para escolher os modelos os [provedores que tem suporte](https://docs.litellm.ai/docs/providers) pelo LiteLLM.\n",
        "\n",
        "No caso, vou usar o GPT-4o, da OpenAI, o llama3-70b, da Meta, mas utilizado através dos serviços da Groq."
      ],
      "metadata": {
        "id": "GFe0zrstft0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "Mu4jD7u3REHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escolha dos modelos\n",
        "Aqui, vamos utilizar um router preditivo para escolher entre dois modelos:\n",
        "- Modelo forte (*strong model*)\n",
        "- Modelo fraco (*weak model*)\n",
        "\n",
        "Além disso, vamos usar o *Matrix Factorization router* para fazer o roteamento. O RouteLLM possui as seguintes opções para routing:\n",
        "-  ***mf***: Usa um modelo de fatorização matricial treinado nos dados de preferência (recomendado)\n",
        "-  ***sw_ranking***: Use um cálculo Elo ponderado para fazer o *routing*, onde cada voto é ponderado de acordo com quão similar é em relação ao prompt do usuário\n",
        "-  ***bert***: Usa o classificador BERT treinado nos dados de preferência\n",
        "-  ***causal_llm***: Usa um classificador baseado em LLM 'fine-tunado' nos dados de preferência\n",
        "-  ***random***: Faz o roteamento aleatório\n",
        "\n",
        "Na maioria dos casos, o uso do MF é recomendado, por ser muito bom e leve."
      ],
      "metadata": {
        "id": "v1hRTQLbhYKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from routellm.controller import Controller\n",
        "client = Controller(\n",
        "  routers=[\"mf\"],\n",
        "  strong_model=\"gpt-4o\",\n",
        "  weak_model=\"groq/llama3-8b-8192\",\n",
        ")"
      ],
      "metadata": {
        "id": "SsF2eV9QSpd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cfd68d0a4287439fbabbb65e45f5dc4d",
            "cd69cb2bd2cf4a0ea8ca03aa203023c6",
            "cc2c144688c645babbfac89debeae81e",
            "d43ba828c8c84e5a8967e08bcdf83f4b",
            "9be006eb6cbc4b478e97fbdcaf7f13a2",
            "0128dc87f6d5433b9f993fcc7de217cc",
            "6733612b234a4199abb7077447b6f637",
            "80a673a0a7984e93a9220e012edc341b",
            "57ba112230a54a229d2a93b58d253334",
            "15ce8bfe1aa3494dbb616f2502184deb",
            "7cd48e26ae454efbb1e73865e85fa0f6"
          ]
        },
        "outputId": "46148a57-1ea1-48a6-91fd-2a2963789452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/820k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfd68d0a4287439fbabbb65e45f5dc4d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obs.**: Mesmo que não utilizemos algum modelo da OpenAI, ainda assim é necessário a chave api dela, porque é utilizado para gerar os embeddings dos routers ***mf*** e ***sw_ranking***.\n",
        "\n",
        "### Definindo limites de custo\n",
        "Cada requisição de roteamento possui um limite de custo que controla o equilíbrio entre custo e qualidade. Devemos calibrar esse limite com base nos tipos de consultas que recebemos para maximizar a performance do roteamento.\n",
        "\n",
        "Como exemplo, vamos calibrar nosso limite para que 50% das chamadas sejam feitas com o GPT-4o, utilizando dados do Chatbot Arena."
      ],
      "metadata": {
        "id": "V7pxdNUsi4dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m routellm.calibrate_threshold --routers mf --strong-model-pct 0.5"
      ],
      "metadata": {
        "id": "0zh_xj5XT4bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bdd082-5fab-4d1c-b00f-4fa9212b9a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md: 100% 418/418 [00:00<00:00, 2.62MB/s]\n",
            "train-00000-of-00001.parquet: 100% 2.11M/2.11M [00:00<00:00, 40.7MB/s]\n",
            "Generating train split: 100% 57477/57477 [00:00<00:00, 870926.76 examples/s]\n",
            "For 50.0% strong model calls for mf, threshold = 0.11593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obs.**: Isso significa que queremos usar 0,11593 como nosso threshold, de modo que aproximadamente 50% de todas as consultas (aquelas que mais exigem o GPT-4o) sejam roteadas para ele.\n",
        "\n",
        "#### Sobre os Thresholds\n",
        "O threshold usado no roteamento controla o equilíbrio entre custo e qualidade. A faixa de valores significativos de threshold varia dependendo do tipo de roteador e das consultas recebidas. Por isso, **recomendo calibrar os thresholds usando uma amostra das suas consultas reais**, além de definir a porcentagem de consultas que você deseja rotear para o modelo mais forte.\n",
        "\n",
        "Por padrão, o RouteLLM oferece suporte à calibração de thresholds com base no dataset público Chatbot Arena. No entanto, observe que como os thresholds são calibrados com base em um dataset existente, a porcentagem real de chamadas roteadas para cada modelo pode variar de acordo com as consultas reais recebidas.\n",
        "\n",
        "Por isso, **recomendo calibrar usando um dataset que se aproxime ao máximo das consultas que você realmente processa**.\n",
        "\n",
        "### Testando o Router\n",
        "Agora, vamos atualizar o campo model ao gerar as respostas para especificar o roteador e o threshold que desejamos usar:"
      ],
      "metadata": {
        "id": "yPWajPsik8_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  # router-[ROUTER]-[LIMIAT]\n",
        "  # Isso diz ao RouteLLM para usar o MF router com um threshold de custo de 0.11593\n",
        "  model=\"router-mf-0.11593\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "id": "tIRMybx3ntdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0daef1d-1b69-48a1-950a-a2268039ad1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelResponse(id='chatcmpl-af4b36b3-620e-4ae2-ad12-61891621a1c3', created=1746387407, model='llama3-8b-8192', object='chat.completion', system_fingerprint='fp_dadc9d6142', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=26, prompt_tokens=12, total_tokens=38, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.019057831, prompt_time=0.001815477, completion_time=0.021666667, total_time=0.023482144), usage_breakdown={'models': None}, x_groq={'id': 'req_01jtect4emenfr4ry7dv311jzw'})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E pronto! Agora, as requisições serão roteadas entre o modelo forte e o modelo fraco conforme a necessidade, **reduzindo custos enquanto mantém uma alta qualidade nas respostas**.\n",
        "\n",
        "Dependendo do seu caso de uso, pode ser interessante:\n",
        "- usar um par de modelos diferente;\n",
        "- modificar a configuração;\n",
        "- ou calibrar os thresholds com base nos tipos de consultas que você realmente recebe — tudo para otimizar a performance do roteador."
      ],
      "metadata": {
        "id": "e9WYVPaqoACl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inicializando um servidor\n",
        "O RouteLLM oferece um servidor leve e compatível com OpenAI para rotear requisições com base em diferentes estratégias de roteamento.\n",
        "\n",
        "- ***--routers*** define a lista de roteadores disponíveis para o servidor. No exemplo abaixo, o servidor é iniciado com um roteador disponível: mf\n",
        "- ***--config*** define o caminho para o arquivo de configuração dos roteadores. Se não for especificado, o servidor usará, por padrão, a configuração de melhor desempenho fornecida.\n",
        "\n",
        "Ao fazer uma requisição para o servidor, o cliente deve especificar o roteador e o threshold de custo a ser usado para cada requisição no campo model, com o seguinte formato:\n",
        "\n",
        "```router-[NOME_DO_ROUTER]-[THRESHOLD]```\n",
        "\n",
        "Por exemplo:\n",
        "\n",
        "```modelo = router-mf-0.5```\n",
        "\n",
        "Isso indica que a requisição deve ser roteada usando o roteador mf com um threshold de 0.5."
      ],
      "metadata": {
        "id": "dhnYb6dPqw14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python -m routellm.openai_server --routers mf --strong-model gpt-4o --weak-model groq/llama3-70b-8192 > server.log 2>&1 &"
      ],
      "metadata": {
        "id": "MXh26bqGUwS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m examples.router_chat --router mf --threshold 0.11593"
      ],
      "metadata": {
        "id": "s3yAbJf9V4lR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753444a0-87ea-47b8-daa4-1e68d65ef71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n",
            "* Running on local URL:  http://127.0.0.1:8001\n",
            "* Running on public URL: https://cfa933a6058b24140f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "<openai.Stream object at 0x7ccad5756b10>\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content='Hello', function_call=None, refusal=None, role='assistant', tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' It', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=\"'s\", function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' nice', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' meet', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' Is', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' there', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' something', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' can', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' help', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' would', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' chat', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' bit', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content='?', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' I', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=\"'m\", function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' here', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' assist', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' any', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' questions', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' or', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' topics', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' you', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=\"'d\", function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' like', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=' discuss', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-d734daa8-90e0-4ab9-9ce6-b3a7ae0f88c8', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason='stop', index=0, logprobs=None)], created=1746386073, model='llama3-70b-8192', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None, provider_specific_fields=None, stream_options=None)\n",
            "<openai.Stream object at 0x7ccad59f0c90>\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='To', function_call=None, refusal=None, role='assistant', tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' find', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' result', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\(', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='frac', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='^', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='746', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='),', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' we', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' first', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' need', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' to', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' calculate', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\(', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='^', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=').\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='First', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' calculate', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\(', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='^', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='):\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='\\\\[', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='^', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' =', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='times', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='times', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386086, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=']\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='Calcul', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='ating', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' gives', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=':\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='\\\\[', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='times', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' =', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='717', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='409', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=']\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='Then', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' multiply', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' by', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' again', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=':\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='\\\\[', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='717', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='409', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='times', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' =', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='607', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='573', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='423', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=']\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='Now', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' divide', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' by', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='746', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=':\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='\\\\[', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='frac', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='607', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='573', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='423', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='746', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='approx', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='814', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='557', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='81', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=']\\n\\n', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='So', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\(', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386087, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='frac', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='847', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='^', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}{', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='746', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='}', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='approx', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='814', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='557', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content='81', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=' \\\\', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=').', function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True}, citations=None)\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason='stop', index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True})\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=None, provider_specific_fields=None, stream_options={'include_usage': True})\n",
            "ChatCompletionChunk(id='chatcmpl-27ec25e0-3071-461e-9f20-90559929c0dd', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None, provider_specific_fields=None, audio=None), finish_reason=None, index=0, logprobs=None)], created=1746386088, model='gpt-4o', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_d8864f8b6b', usage=CompletionUsage(completion_tokens=154, prompt_tokens=81, total_tokens=235, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), provider_specific_fields=None, stream_options={'include_usage': True})\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3019, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/examples/router_chat.py\", line 98, in <module>\n",
            "    ).queue().launch(server_name=args.host, server_port=args.port, share=True)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2925, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3023, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:8001 <> https://cfa933a6058b24140f.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roteamento Não-Preditivo\n"
      ],
      "metadata": {
        "id": "OPuFRccbz6WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execução Paralela\n",
        "\n",
        "Este notebook demonstra dois tipos de roteamento não-preditivo:\n",
        "\n",
        "1. **Cascata (Stage-up):** sobe progressivamente entre modelos baratos → intermediários → caros, apenas se necessário.\n",
        "2. **Execução Paralela:** todos os modelos geram respostas ao mesmo tempo, e um LLM escolhe a melhor.\n",
        "\n",
        "Usaremos o modelo `llama3-70b-8192` via Groq como julgador."
      ],
      "metadata": {
        "id": "V1KTuutr3IeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "from openai import ChatCompletion\n",
        "\n",
        "client_groq = Groq(api_key = userdata.get(\"GROQ_API_KEY\"))"
      ],
      "metadata": {
        "id": "GBz5pjGB3IOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def julgar_resposta(modelo, resposta, pergunta):\n",
        "    prompt = f\"\"\"\n",
        "    Você é um avaliador de qualidade de respostas geradas por IA.\n",
        "    Sua tarefa é dizer se a resposta abaixo é suficiente para a pergunta, com base em completude, exatidão e clareza.\n",
        "\n",
        "    Pergunta: {pergunta}\n",
        "\n",
        "    Resposta do modelo {modelo}: {resposta}\n",
        "\n",
        "    Responda apenas com \"ACEITA\" ou \"REJEITA\", sem explicações.\n",
        "    \"\"\"\n",
        "\n",
        "    resposta = client_groq.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return resposta.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "H4coJoVQ3eMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roteamento em Cascata"
      ],
      "metadata": {
        "id": "q2quM4EB4OwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta = \"A que temperatura a água ferve ao nível do mar?\"\n",
        "resposta_mistral = \"A água ferve em olá, olá!!!\"\n",
        "\n",
        "if julgar_resposta(\"mistral\", resposta_mistral, pergunta).strip().upper() == \"ACEITA\":\n",
        "    print(\"✅ Mistral aceito\")\n",
        "else:\n",
        "    print(\"Mistral não aceito.\")\n",
        "    resposta_deepseek = \"Ao nível do mar, a água entra em ebulição a 100 graus Celsius.\"\n",
        "    if julgar_resposta(\"deepseek\", resposta_deepseek, pergunta).strip().upper() == \"ACEITA\":\n",
        "        print(\"✅ DeepSeek aceito\")\n",
        "    else:\n",
        "        resposta_gpt4 = \"A água entra em ebulição exatamente a 100°C ao nível do mar, sob pressão atmosférica padrão.\"\n",
        "        print(\"✅ GPT-4 enviado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjqLnDoe3xRo",
        "outputId": "69750193-e9ea-4ccf-f043-20966eafa61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral não aceito.\n",
            "✅ DeepSeek aceito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Julgamento Paralelo"
      ],
      "metadata": {
        "id": "1T5nCNPb5E0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def escolher_melhor_resposta(modelos_e_respostas, pergunta):\n",
        "    comparativo = \"\\n\\n\".join(\n",
        "        [f\"Resposta de {modelo}:\\n{resposta}\" for modelo, resposta in modelos_e_respostas.items()]\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Você é um avaliador de qualidade de respostas geradas por IA.\n",
        "    Sua tarefa é analisar as respostas abaixo para a mesma pergunta e indicar **qual delas é a melhor** com base em completude, exatidão e clareza.\n",
        "\n",
        "    Pergunta: {pergunta}\n",
        "\n",
        "    {comparativo}\n",
        "\n",
        "    Responda apenas com o nome do modelo. Sem explicações.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client_groq.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "vRh2R6Dm4aYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respostas = {\n",
        "    \"mistral\": \"A água ferve em 100 graus.\",\n",
        "    \"deepseek\": \"Ao nível do mar, a água entra em ebulição a 100 graus Celsius.\",\n",
        "    \"gpt-4\": \"A água entra em ebulição exatamente a 100°C ao nível do mar, sob pressão atmosférica padrão.\"\n",
        "}\n",
        "\n",
        "modelo_escolhido = escolher_melhor_resposta(respostas, pergunta)\n",
        "print(f\"🎯 Melhor resposta: {modelo_escolhido}\")\n",
        "print(\"Resposta retornada:\", respostas[modelo_escolhido])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GynnEyF85YMR",
        "outputId": "35119c29-f634-4885-f8a6-dfafb37d18ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Melhor resposta: gpt-4\n",
            "Resposta retornada: A água entra em ebulição exatamente a 100°C ao nível do mar, sob pressão atmosférica padrão.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Router Híbrido\n",
        "\n",
        "Este notebook executa uma abordagem híbrida realista:\n",
        "\n",
        "1. Usa `RouteLLM` com o roteador `mf` para prever se o modelo leve pode ser usado.\n",
        "2. Se for possível, executa o modelo leve (`llama3-70b` da Groq).\n",
        "3. A resposta é julgada com um LLM (o próprio LLaMA3 via Groq).\n",
        "4. Se a resposta for rejeitada, sobe para `GPT-4o`.\n",
        "\n",
        "Economiza quando possível, garante qualidade quando necessário."
      ],
      "metadata": {
        "id": "d_THJTaL7kMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "controller = Controller(\n",
        "    routers=[\"mf\"],\n",
        "    strong_model=\"gpt-4o\",\n",
        "    weak_model=\"groq/llama3-70b-8192\",\n",
        ")\n",
        "\n",
        "# Setup Groq client para usar como julgador\n",
        "judge = Groq(api_key=\"SUA_GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "EAw0_LKi775x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def chamar_openai(pergunta):\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "    data = {\n",
        "        \"model\": \"gpt-4o\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"developer\", \"content\": \"You are a helpful assistant that answers in pt-BR.\"},\n",
        "            {\"role\": \"user\", \"content\": pergunta}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    response.raise_for_status()  # lança erro se falhar\n",
        "\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "aN2A6PxTw6iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta = \"how much is 484ˆ4 divided by 38?\"\n",
        "\n",
        "# Etapa 1: previsão com o roteador (sem execução ainda)\n",
        "response = controller.chat.completions.create(\n",
        "      model=\"router-mf-0.11593\",\n",
        "      messages=[{\"role\": \"user\", \"content\": pergunta}])\n",
        "\n",
        "roteado_para = response.model\n",
        "\n",
        "if roteado_para == \"llama3-70b-8192\":\n",
        "    print(\"🔄 RouteLLM indicou uso do modelo leve (Groq LLaMA3).\")\n",
        "\n",
        "    # Executa modelo leve\n",
        "    resposta_leve = response.choices[0].message.content\n",
        "\n",
        "    # Julga qualidade\n",
        "    veredito = julgar_resposta(\"llama3\", resposta_leve, pergunta)\n",
        "\n",
        "    if veredito == \"ACEITA\":\n",
        "        print(\"✅ Resposta do modelo leve foi aceita.\")\n",
        "        print(resposta_leve)\n",
        "    else:\n",
        "        print(\"🔁 Subindo para GPT-4o...\")\n",
        "        resposta_forte = chamar_openai(pergunta)\n",
        "        print(\"✅ Resposta final do GPT-4o:\")\n",
        "        print(resposta_forte)\n",
        "\n",
        "else:\n",
        "    print(\"🔼 RouteLLM já recomendou direto o modelo forte (GPT-4o).\")\n",
        "    resposta_forte = response.choices[0].message.content\n",
        "    print(\"✅ Resposta do GPT-4o:\")\n",
        "    print(resposta_forte)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kw30bz379JF",
        "outputId": "68b35888-b3ce-4fa5-838a-335c2dd99d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔼 RouteLLM já recomendou direto o modelo forte (GPT-4o).\n",
            "✅ Resposta do GPT-4o:\n",
            "To find the value of \\(484^4\\) divided by 38, we need to first calculate \\(484^4\\) and then divide the result by 38.\n",
            "\n",
            "1. Calculate \\(484^4\\):\n",
            "\n",
            "   \\[\n",
            "   484^4 = (484 \\times 484) \\times (484 \\times 484)\n",
            "   \\]\n",
            "\n",
            "   First, calculate \\(484 \\times 484\\):\n",
            "\n",
            "   \\[\n",
            "   484 \\times 484 = 234,256\n",
            "   \\]\n",
            "\n",
            "   Then, multiply the result by itself to find \\(484^4\\):\n",
            "\n",
            "   \\[\n",
            "   234,256^2 = 54,595,979,776\n",
            "   \\]\n",
            "\n",
            "2. Divide the result by 38:\n",
            "\n",
            "   \\[\n",
            "   \\frac{54,595,979,776}{38} \\approx 1,436,736,309.368\n",
            "   \\]\n",
            "\n",
            "So, \\(484^4\\) divided by 38 is approximately 1,436,736,309.368.\n"
          ]
        }
      ]
    }
  ]
}